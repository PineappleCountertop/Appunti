---
tags: [Analisi II, Esportati]
title: Analisi II - quarta parte bis
created: '2020-01-20T19:29:30.391Z'
modified: '2020-01-23T11:22:29.193Z'
---

# Analisi II - quarta parte bis
## Conseguenza del teorema del valor medio
+ Teorema
Se $f:A(\subseteq\mathbb{R}^n)\to\mathbb{R}$ differenziabile in $A$ aperto e connesso ha $\nabla  f(\underline{x})=\underline{0}$ allora $\exists c\in \mathbb{R}$ t.c. $f(\underline{x})=c$ in $A$.
  * Dimostrazione (Idea)
  Fissiamo $\underline{x_0}\in A$ e consideriamo un generico $\underline{x}\in A$. Poichè $A$ è connesso si può provare che esiste una poligonale di vertici $\underline{x}^0,...,\underline{x}^n=\underline{x}$ interamente contenuta in $A$, $\forall k=0,...,n-1$ il teorema del valor medio applicato al segmento di estremi $\underline{x}^k, \underline{x}^{k+1}$ implica che $f(\underline{x}^{k+1})=f(\underline{x}^k)=<\nabla f(\underline{x}^k)+\vartheta(\underline{x}^{k+1}-\underline{x}^k)),\underline{x}^{k+1}-\underline{x}^k>=0$. Quindi si conclude che $f(\underline{x}^{k+1})=f(\underline{x}^{k})$, $\forall k=0,...,1$ e dunque $f(\underline{x})=f(\underline{x^0})=c$, $\forall \underline{x}\in A$
## Derivarte direzionali e parziali di ordine superiore
Sia $f:A(\subseteq\mathbb{R}^n)\to\mathbb{R}$, $A$ aperto e sia $\underline{u}\in \mathbb{R}^n$ un versore. Supponiamo che esista $\displaystyle \frac{\partial f}{\partial \underline{u}}(\underline{x})$ in $A$. Resta così definita $\displaystyle \frac{\partial f}{\partial \underline{u}}:A(\subseteq \mathbb{R}^n)\to \mathbb{R}$. Siano $\underline{v}\in \mathbb{R}^n$ un versore e $\underline{x_0}\in A$. Se esiste $\displaystyle \frac{\partial }{\partial \underline{v}}\left(\frac{\partial f}{\partial \underline{u}}\right)(\underline{x_0})$ questa si dice derivata direzionale seconda di $f$ in $\underline{x_0}$ lungo la direzione orientata $\underline{u}$ e $\underline{v}$ nell'ordine e si indica con $\displaystyle f_{\underline{u}\underline{v}}=\frac{\partial^2 f}{\partial \underline{u}\partial \underline{v}}(\underline{x_0})$
Iterando il processo si definiscono le derivate direzionali successive.
+ Sia $f:A(\subseteq\mathbb{R}^n)\to\mathbb{R}$, $A$ aperto. Supponiamo che esista $\displaystyle \frac{\partial f}{\partial \underline{x_i}}(\underline{x})$ in $A$. Resta così definita $\displaystyle \frac{\partial f}{\partial \underline{x_i}}:A(\subseteq \mathbb{R}^n)\to \mathbb{R}$
+ Sia $\underline{x_0}\in A$. Se esiste $\displaystyle \frac{\partial }{\partial x_j}\left(\frac{\partial f}{\partial x_i}\right)(\underline{x}^0)$ questa si dice derivata parziale seconda di $f$ in $\underline{x_0}$ rispetto a $x_i$ e $x_j$ nell'ordine e si indica con $f_{x_ix_j}(\underline{x^0})=\displaystyle \frac{\partial^2f}{\partial x_j\partial x_i}(\underline{x}^0)$
Analogamente si definisce la derivata parziale di ordine superiore
## Funzioni di classe $C^k$
Sia $f:A(\subseteq\mathbb{R}^n)\to\mathbb{R}$ $A$ aperto, si dice che $f$ è di classe $C^k$ in $A$ e si scrive $f\in C^k(A)$ se $f$ è dotata di tutte le derivate parziali fino all'ordine $k$ e queste sono continue in $A$.
## Teorema di Schwartz
Se $f:A(\subseteq\mathbb{R}^n)\to\mathbb{R}$, $A$ aperto, è di classe $C^k$ in $A$ allora le derivate miste $h$-esime, con $2\le h\le k$ __non__ dipendono dall'ordine seguiteo nell'eseguire la derivazione
## Forme lineari e forme quadratiche
+ Un'applicazione $L:\mathbb{R}^n\to \mathbb{R}$, $L(\underline{h})=\sum a_ih_i=<\underline{a},\underline{h}>$, con $\underline{a}=(a_1,...,a_n)^T$, è detta forma lineare in $\mathbb{R}^n$. Se $L\neq 0$ allora $L$ è un polinomio omogeneo di $I$ grado nelle variabili $\ell_1,...,\ell_n$.
+ Un'applicazione $Q:\mathbb{R}^n\to \mathbb{R}$, $Q(\underline{h})=\sum\sum a_{ij}h_jh_i=<\mathbb{A}\cdot \underline{h},\underline{h}>$, con $\mathbb{A}=\begin{pmatrix} a_{11} ... a_{1n} \\ \vdots\text{   }\ddots\text{   }\vdots\\ a_{n1} ... a_{nn}\end{pmatrix}$, è detta forma quadratica in $\mathbb{R}^n$.
## Proprietà delle forme quadratiche
Sia $\mathbb{A}\in M(n,n)$ e $\underline{h},\underline{k}\in \mathbb{R}^n$. Si ha:
1. $<\mathbb{A}\cdot \underline{h},\underline{k}>=<\underline{h},\mathbb{A}\cdot \underline{k}>$. Infatti $<\mathbb{A}\cdot \underline{h},\underline{k}>=\sum(\sum a_{ij}\cdot h_j)k_i=\sum(\sum a_{ij}\cdot k_j)h_i$.
2. Se $Q(\underline{h})=<\mathbb{A}\underline{h},\underline{h}>$, allora posto $\mathbb{A}^s=\frac{1}{2}(\mathbb{A}+\mathbb{A}^T)$, $\mathbb{A}^s$ è simmetrica. $Q(\underline{h})=<\mathbb{A}^s\cdot\underline{h},\underline{h}$. Infatti $Q(\underline{h})=<\mathbb{A}\cdot\underline{h},\underline{h}=<\underline{h},\mathbb{A}^T\cdot \underline{h}>$ e quindi $2\cdot Q(\underline{h})=<\mathbb{A}\cdot\underline{h},\underline{h}+<\underline{h},\mathbb{A}^T\cdot \underline{h}>=<(\mathbb{A}+\mathbb{A}^T)\cdot \underline{h},\underline{h}>$. Dunque $Q(\underline{h})=<\frac{1}{2}(\mathbb{A}+\mathbb{A}^T)\cdot \underline{h},\underline{h}>$
non è restrittivo supporre che $\displaystyle \mathbb{A}=\mathbb{A^s}$
3. 
    - Se $L$ è una forma lineare, $L(\underline{h})=<\underline{a},\underline{h}>$, si ha $\displaystyle \nabla <\underline{a},\underline{h}>=(\frac{\partial }{\partial h_1}a_1h_1,...,\frac{\partial }{\partial h_n}a_nh_n)=\underline{a}$   (in quanto $\frac{\partial }{\partial h_i}a_ih_i=a_i$)
    - Se $Q$ è una forma quadratica con $Q(\underline{h})=<\mathbb{A}\cdot \underline{h},\underline{h}>$, $\nabla<\mathbb{A}\cdot \underline{h},\underline{h}>=(\mathbb{A}+\mathbb{A}^T)\cdot \underline{h}=2\mathbb{A}^s\cdot \underline{h}$. Infatti per $N=2$: $\nabla\cdot(<\mathbb{A}\cdot \underline{h},\underline{h}>)=\nabla(a_1h_1^2+...+a_nh_n^2)=\begin{pmatrix} 2a_{11}h_1+a_{12}h_2+a_{21}h_2 \\ a_{12}h_1+a_{21}h_1+2a_{22}h_1 \\ \end{pmatrix}=\begin{pmatrix}  2a_{11}+a_{12}+a_{21} \\ a_{12}+a_{21}+2a_{22} \end{pmatrix}\cdot \begin{pmatrix} h_1 \\ h_2 \end{pmatrix}=\left[\begin{pmatrix} a_{11} a_{12} \\ a_{21} a_{22} \end{pmatrix}+\begin{pmatrix} a_{11} a_{21} \\ a_{12} a_{22} \end{pmatrix}\right]\begin{pmatrix} h_1 \\ h_2 \end{pmatrix}=(\mathbb{A}+\mathbb{A}^T)\cdot \underline{h}$
  
## Differenziale per campi scalari
Sia $f:A(\subseteq\mathbb{R}^n)\to\mathbb{R}$, $A$ aperto, differenziabile in $A$ e sia $\underline{x}^0\in A$. Sia $g=\nabla f$ in $\underline{x}^0$. Si chiama matrice __Hessiana__ di $f$ in $\underline{x}^0$ e risulta $\displaystyle Hf(\underline{x}^0)=Jg(\underline{x}^0=J(\nabla f)(\underline{x}^0)=\begin{pmatrix} \displaystyle \frac{\partial g_1}{x_1}(\underline{x}^0) \dots \frac{\partial g_1}{x_n}(\underline{x}^0) \\ \vdots\text{          }\ddots\text{          }\vdots \\ \displaystyle  \frac{\partial g_n}{x_1}(\underline{x}^0) \dots \frac{\partial g_n}{x_n}(\underline{x}^0)  \end{pmatrix}=\begin{pmatrix} \displaystyle \frac{\partial^2 f}{\partial x_1^2}\dots\frac{\partial^2 f}{\partial x_ix_n}  \\ \vdots\text{          }\ddots\text{          }\vdots \\ \displaystyle \frac{\partial^2 f}{\partial x_nx_1}\dots\frac{\partial^2 f}{\partial x_n^2} \end{pmatrix}\in M(n,n)$. La matrice Hessiana è la matrice di tutte le derivate parziali seconde.
La forma quadratica $Q(\underline{h})=<Hf(\underline{x}^0)\cdot \underline{h},\underline{h}>=d^2f(\underline{x}^0)=\sum(\sum\frac{\partial^2f}{\partial x_i\partial x_j}(\underline{x}^0)h_j)h_i$

## Teorema di Young (sulla simmetrica delle matrici Hessiane)
Se $f$ è due volte differenziabile in $\underline{x}^0$, allora $Hf(\underline{x}^0)$ è simmetrica, cioè $\frac{\partial^2f}{\partial x_i\partial x_j}(\underline{x}^0)=\frac{\partial^2f}{\partial x_j\partial x_i}(\underline{x}^0)$.
### Condizione sufficiente affinchè una $f$ sia due volte differenziabile
Se $f\in C^2(A)$, $A$ aperto, allora $f$ è due volte differenziabile in ogni punto di $A$. Inoltre $g=\nabla f\in C^1(A)$. Se $g\in C^1(A)\Rightarrow g$ è differenziabile in $A$ si conclude che $f$ è due volte differenziabile in $A$
## Teorema (formula di Taylor di ordine $II$)
Se $f$ è due volte differenziabile in $\underline{x}^0$, allora $f(\underline{x})=f(\underline{x}^0)+<\nabla f(\underline{x}^0),\underline{x}-\underline{x}^0>+\frac{1}{2}<Hf(\underline{x}^0)(\underline{x}-\underline{x_0}),\underline{x}-\underline{x}^0>+o(||\underline{x}-\underline{x}^0||)$, approssimazione quadratica di $f$ in $\underline{x}^0$ o polinomio di Taylor di $f$ in $\underline{x}^0$ di ordine $II$
## Dimostrazione
Poniamo $φ(\underline{x})=f(\underline{x})-(f(\underline{x}^0)+<\nabla f(\underline{x}^0),\underline{x}-\underline{x}^0>+\frac{1}{2}<Hf(\underline{x}^0)(\underline{x}-\underline{x_0}),\underline{x}-\underline{x}^0>+o(||\underline{x}-\underline{x}^0||))$. Proviamo che $φ(\underline{x})=o(||\underline{x}-\underline{x}^0||)$.
Poichè $f$ è differenziabile in $\underline{x}^0$, anche $φ$ è differenziabile in $\underline{x}^0$ e $\nabla φ(\underline{x})=\nabla f(\underline{x})-\nabla f(\underline{x}^0)-Hf(\underline{x}^0)(\underline{x}-\underline{x}^0)$. Poichè $\nabla f$ è differenziabile in $\underline{x}^0$, si ha che $\nabla φ(\underline{x})=o(||\underline{x}-\underline{x}^0||)$. Applichiamo il teorema del valor medio a $φ$: $φ(\underline{x})-\cancel{φ(\underline{x}^0)}=<\nabla φ(\underline{x}^0+\vartheta(\underline{x}-\underline{x}^0)),\underline{x}-\underline{x}^0>$, per qualche $ϑ\in ]0,1[$ e quindi $|φ(\underline{x})|=|<\nabla φ(\underline{x}^0+\vartheta(\underline{x}-\underline{x}^0)),\underline{x}-\underline{x}^0>|\le ||\nabla φ(\underline{x}^0+ϑ(\underline{x}-\underline{x}^0))||\cdot ||\underline{x}-\underline{x}^0||\overset{C-S}{=}\displaystyle \frac{||o(||ϑ(\underline{x}-\underline{x}^0)||)||\cdot||\underline{x}-\underline{x}^0||^2}{ϑ||\underline{x}-\underline{x}^0||}\overset{\underline{x}\to \underline{x}^0}{<}o(||\underline{x}-\underline{x}^0||^2)$
## Punti di minimo e massimo relativo
Sia $f:E(\subseteq\mathbb{R}^n)\to\mathbb{R}$, un punto $\underline{x}^0\in E$. Si dice minimo (massimo) relativo per $f$ se esiste un intorno $U$ di $\underline{x}^0$ t.c. $f(\underline{x})\underset{(<)}{>}f(\underline{x}^0)$, $\forall \underline{x}\in U\cap E$
## Studio degli estremi liberi 
### Test del quoziente o tesi di Fermat (condizione necessaria per l'esistenza del punto di estremo)
Se $f:E(\subseteq\mathbb{R}^n)\to\mathbb{R}$ è differenziabile in $\underline{x}^0\in intE$ e $\underline{x}^0$ è punto di estremo relativo per $f$ allora $\nabla f(\underline{x}^0)=\underline{0}$.
### Dimostrazione
Fissato un versore $\underline{u}\in \mathbb{R}^n$. Poichè $\underline{x}^0\in intE$ esiste $δ>0$ t.c. $\underline{x}=\underline{x}^0+t\underline{u}\in E$, $\forall |t|<δ$. Poniamo $g(t)=f(\underline{x}^0+t\underline{u})$, $\forall |t|<δ$. Poichè $f$ ha un punto di minimo in $\underline{x}^0$, $g$ ha un punto di minimo in $t=0$, $0\in ]-δ,δ[$ ed è derivabile in $0$, essendo la composta di funzioni differenziabile e derivabile. Per il teorema di Fermat unidimensionale si ha $\displaystyle 0=g'(0)=<\nabla f(\underline{x}^0),\underline{u}>=\frac{\partial f}{\partial \underline{u}}(\underline{x}^0)$. In particolare risulta $\displaystyle \frac{\partial f}{\partial x_i}(\underline{x}^0)=0$, per $i=1,...,n$, cioè $\displaystyle \nabla f(\underline{x}^0)=\underline{0}$
## Punti critici
Sia $f:E(\subseteq\mathbb{R}^n)\to\mathbb{R}$ differenziabile in $\underline{x}^0\in intE$. Si dice che $\underline{x}^0$ è punto critico per $f$ se $\nabla f(\underline{x}^0)=0$
## Punto di sella
Un punto critico $\underline{x}^0$ per $f$ si dice punto di sella per $f$ se esistono due versori $\underline{u},\underline{v}\in \mathbb{R}^n$ linearmente indipendenti t.c. posto $g(t)=f(\underline{x}^0+t\underline{u})$ e $h(t)=f(\underline{x}^0+t\underline{v})$, $\forall |t|<δ$, $g$ ha un punto di minimo relativo per $t=0$ e $h$ ha un punto di massimo relativo per $t=0$
## Studio della natura dei punti critici
### Segno di una forma quadratica (o di una matrice simmetrica)
Sia $Q(\underline{h}):\mathbb{R}^n\to \mathbb{R}$ una forma quadratica con $Q(\underline{h})=<\mathbb{A}\cdot \underline{h},\underline{h}>$ dove $\mathbb{A}$ è una matrice simmetrica $N\times N$.
Si dice che:
+ $Q$ (o $\mathbb{A}$) è definita positiva se $Q(\underline{h})>0$, $\forall \underline{h}\neq \underline{0}$
+ $Q$ (o $\mathbb{A}$) è definita negativa se $Q(\underline{h})<0$, $\forall \underline{h}\neq \underline{0}$
+ $Q$ è indefinita nel segno se esistono $\underline{u},\underline{v}$ t.c. $Q(\underline{u})>0$ $\wedge$ $Q(\underline{v})<0$
## Criteri di definitezza
Sia $Q:\mathbb{R}^n\to \mathbb{R}$ una forma quadratica, esiste $\mathbb{A}(n,n)$ simmetrica t.c. $Q(\underline{h})=<\mathbb{A}\cdot \underline{h},\underline{h}>$, $\forall \underline{h}\in \mathbb{R}^n$. $\mathbb{A}$ ha $n$ autovalori reali: $λ_1,...,λ_n$ e $n$ autovettori $\underline{u}_1,...,\underline{u}_n$ t.c. $\mathbb{A}\cdot \underline{u}_i=λ_i\underline{u}_i$, per $i=1,...,n$ e li scelgo in modo da avere: $<\underline{u}_i,\underline{u}_j>=\begin{pmatrix} 1 \text{ se } i=j \\ 0 \text{ se } i\neq j \end{pmatrix}=δ_{ij}$, per $i,j=1,...,n$
Rango di una matrice di autovettori: $\mathbb{U}=(u_1,...,u_n)$ e definisco la matrice diagonale $λ=\begin{pmatrix} λ_1 & \dots& 0 \\0 & \ddots & \vdots &\\ 0& \dots& λ_n \end{pmatrix}$. Si ha $\mathbb{U}^t\cdot \mathbb{U}=I_n$, ossia $\mathbb{U}^T=\mathbb{U}^{-1}$ e $\mathbb{U}^T\mathbb{A}\mathbb{U}=λ\Leftrightarrow \mathbb{A}\mathbb{U}=\mathbb{U}λ$, con $λ_i$ radice di $det(\mathbb{A-tI_n})$.
## Proposizione
$Q$ è definita positiva $\Leftrightarrow$ $λ_1>0,...,λ_n>0$. $Q$ è definita negativa $\Leftrightarrow$ $λ_1<0,...,λ_n<0$. $Q$ è invece indefinita nel segno $\Leftrightarrow$ esistono $i,j$ t.c. $λ_i<0<λ_j$
## Dimostrazione
Prendo $\underline{h}\in \mathbb{R}^n$. Esiste uno ed un solo $\underline{k}\in \mathbb{R}^n$ t.c. $\underline{h}=\mathbb{U}\cdot \underline{k}$. Si ha $Q(\underline{h})=<\mathbb{A}\cdot \underline{h},\underline{h}>=<\mathbb{A}\mathbb{U}\underline{k},\mathbb{U}\underline{k}>$, per le proprietà delle forme quadratiche: $<\mathbb{A}\mathbb{U}\underline{k},\mathbb{U}\underline{k}>=<\mathbb{U}^T\mathbb{A}\mathbb{U}\underline{k},\underline{k}>=<λ\underline{k},\underline{k}>=<\begin{pmatrix} λ_1k_1 \\ \vdots \\ λ_nk_n \end{pmatrix},\begin{pmatrix} k_1 \\ \vdots \\ k_n \end{pmatrix}>=λ_1k_1^2+...+λ_nk_n^2$. Si deduce quindi immediatamente il criterio enunciato.
## Criterio di Sylvester
$Q$ è definita positiva $\Leftrightarrow$ dato $\mathbb{A}=\begin{pmatrix} a_{11} & \dots & a_{1n} \\ \vdots&\ddots&\vdots \\ a_{n1}&\dots&a_{nn} \end{pmatrix}$, simmetrica, $A_1=a_{11}>0$, $A_2=det\begin{pmatrix} a_{11}&a_{12}\\ a_{12}&a_{22} \end{pmatrix}>0,...,A_n=det\mathbb{A}>0$. $Q$ è invece definita negativa $\Leftrightarrow$ $A_1<0, A_2>0,...,(-1)^nA_n>0$
## Lemma
$Q$ è definita positiva $\Leftrightarrow$ $\exists m>0$ t.c. $Q(\underline{h})\ge m||\underline{h}||^2$ per ogni $\underline{h}\in \mathbb{R}^n$. $Q$ è definita negativa $\Leftrightarrow$ $\exists M<0$ t.c. $Q(\underline{h})\le M||\underline{h}||^2$, per ogni $\underline{h}\in \mathbb{R}^n$
## Dimostrazione
$Q$ è definita positiva $\Leftrightarrow$ $λ_1>0,...,λ_n>0$. Pongo $m=min\{λ_1,...,λ_n\}>0$. Allora $\forall \underline{h}\in \mathbb{R}^n$ esiste $\underline{k}\in \mathbb{R}^n$ t.c. $\underline{h}=\mathbb{U}\underline{k}$. Si ha $Q(\underline{h})=λ_1k_1^2+...+λ_nk_n^2\ge mk_1^2+...+mk_n^2=m||\underline{k}||^2=m||\mathbb{U}^T\underline{h}||^2=m||\underline{h}||^2$, essendo $\mathbb{U}$ ortogonale
## Test Hessiana (condizione sufficiente per l'esistenza di un punto di estremo)
### Teorema
Sia $f:E(\subseteq\mathbb{R}^n)\to\mathbb{R}$ due volte differenziabile in $\underline{x}^0\in intE$ e sia $\underline{x}^0$ un punto criticodi $f$, ossia $\nabla f(\underline{x}^0)=\underline{0}$. Si ha:
1. Se $Hf(\underline{x}^0)$ è definita positiva, allora $\underline{x}^0$ è punto di minimo per $f$
2. Se $Hf(\underline{x}^0)$ è definita negativa, allora $\underline{x}^0$ è punto di massimo per $f$ 
3. Se $Hf(\underline{x}^0)$ è indefinita nel segno, allora $\underline{x}^0$ è punto di sella per $f$
### Dimostrazione
$f(\underline{x}^0)=f(\underline{x}^0)+<\nabla f(\underline{x}^0),\underline{x}-\underline{x}^0>+\frac{1}{2}<Hf(\underline{x}^0)(\underline{x}-\underline{x}^0),\underline{x}-\underline{x}^0>+o(||\underline{x}-\underline{x}_0||^2)$. Il punto è critico $\Rightarrow$ $\nabla f(\underline{x}^0)=\underline{0}$ $\Rightarrow$ $<\nabla f(\underline{x}^0),\underline{x}-\underline{x}^0>=0$. Allora: $f(\underline{x})-f(\underline{x}^0)=\frac{1}{2}<Hf(\underline{x}^0)(\underline{x}-\underline{x}^0),\underline{x}-\underline{x}^0>+o(||\underline{x}-\underline{x}_0||^2)$. Nel primo caso $Hf(\underline{x}^0)$ è definita positiva e quindi $\exists m>0$ t.c. $<Hf(\underline{x}^0)\underline{h},\underline{h}>\ge m||\underline{h}||^2$, $\forall \underline{h}\in \mathbb{R}^n$. Allora risulta che la funzione $\displaystyle f(\underline{x})-f(\underline{x}^0)=\frac{1}{2}<Hf(\underline{x}^0)(\underline{x}-\underline{x}^0),\underline{x}-\underline{x}^0>+o(||\underline{x}-\underline{x}_0||^2)\ge \frac{m}{2}||\underline{x}-\underline{x}^0||^2+o(||\underline{x}-\underline{x}^0||^2)=\left(\frac{m}{2}+\frac{o(||\underline{x}-\underline{x}^0||^2)}{||\underline{x}-\underline{x}^0||^2}\right)||\underline{x}-\underline{x}^0||^2$. Poichè $\displaystyle\lim_{\underline{x}\to \underline{x}^0}\left(\frac{m}{2}+\frac{o(||\underline{x}-\underline{x}^0||^2)}{||\underline{x}-\underline{x}^0||^2}\right)=\frac{m}{2}>0$ e, per il teorema di permanenza del segno esiste un intorno $U$ di $\underline{x}^0$ tale per cui $\frac{m}{2}+\frac{o(||\underline{x}-\underline{x}^0||^2)}{||\underline{x}-\underline{x}^0||^2}>0$, $\forall \underline{x}\in U\cap E$, con $\underline{x}\neq \underline{x}^0$. Ne segue che $f(\underline{x})-f\underline{x}^0)>0$, $\forall \underline{x}\in U\cap E$, con $\underline{x}\neq \underline{x}^0$, ossia $\underline{x}^0$ è punto di minimo relativo, la situazione è analoga per il secondo caso.
Nel terzo caso: $Hf(\underline{x}^0)$ è indefinita nel segno, quindi $\exists \underline{u},\underline{v}\in \mathbb{R}^n$, versori, t.c. $<Hf(\underline{x}^0)\underline{u},\underline{u}><0<<Hf(\underline{x}^0)\underline{v},\underline{v}>)$. Pongo $g(t)=f(\underline{x}^0+t\underline{u})$ e $h(t)=f(\underline{x}^0+t\underline{v})$. Ho che $\displaystyle g(t)-g(0)=f(\underline{x}^0+t\underline{u})-f(\underline{x}^0)=\frac{1}{2}<Hf(\underline{x}^0)t\underline{u},t\underline{u}>+o(||t\underline{x}^0||^2)$.
Ossia: $\frac{1}{2}<Hf(\underline{x}^0)t\underline{u},t\underline{u}>+o(||t\underline{x}^0||^2)=\frac{t^2}{2}<Hf(\underline{x}^0)\underline{u},\underline{u}+o(t^2)=\left(\frac{1}{2}<Hf(\underline{x}^0)\underline{u},\underline{u}>+\frac{o(t^2)}{t^2}\right)t^2$.
Ma allora: $\displaystyle\lim_{t\to 0} \left(\frac{1}{2}<Hf(\underline{x}^0)\underline{u},\underline{u}>+\frac{o(t^2)}{t^2}\right)t^2=\frac{1}{2}<Hf(\underline{x}^0)\underline{u},\underline{u})><0$. Allora per il teorema di permanenza del segno esiste $δ>0$ t.c. $\frac{1}{2}<Hf(\underline{x}^0)\underline{u},\underline{u})>+\frac{o(t^2)}{t^2}>0$, per $0<|t|<δ$ e quindi $g(t)-g(0)<0$, $\forall 0<|t|<δ$, ossia $g$ ha un massimo in $t=0$. Ugualmente si verificache $h$ ha un minimo in $t=0$, ossia $\underline{x}^0$ è un punto di sella.
## Teorema
Sia $f:\mathbb{R}^n\to \mathbb{R}$ continua e $\displaystyle\lim_{||\underline{x}^0\to +\infty||}f(\underline{x}^0)=+\infty$ allora esiste $\underset{\mathbb{R}^n}{min}f$, concetto simile alla coercività di $\mathbb{R}$. Analogmente se $\displaystyle\lim_{||\underline{x}^0\to +\infty||}f(\underline{x}^0)=+\infty$ allora esiste  $\underset{\mathbb{R}^n}{max}f$, concetto simile all'anticoercività di $\mathbb{R}$.




